{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wand.image import Image\n",
    "from PIL import Image as PI\n",
    "import pyocr\n",
    "import pyocr.builders\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = pyocr.get_available_tools()[0]\n",
    "lang = tool.get_available_languages()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "req_image = []\n",
    "final_text = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_pdf = Image(filename=\"test.pdf\", resolution=100)\n",
    "image_jpeg = image_pdf.convert('jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1912,06612v1 [cs.AI] 13 Dec 2019\\n\\narXiv\\n\\nFrom Shallow to Deep Interactions Between Knowledge\\nRepresentation, Reasoning and Machine Learning\\n\\nKay R. Amel!\\nGDR Aspects Formels et Algorithmiques de lIntelligence Artificielle\\nCNRS\\n\\nDecember 16, 2019\\n\\nAbstract\\n\\n‘This paper proposes a tentative and orginal survey of meeting points between Knowledge Repre-\\nsentation and Reasoning (KAR) and Machine Learning (ML), two areas which have been developing\\nquite separately in the last three decades. Some common concems are Kentifled and discussed such\\nas the types of used representation, the roles of knowledge and data, the lack or the excess of infor-\\nmation, or the need for explanations and causal understanding. Then some methodologies combining\\nreasoning and learning are reviewed (such as inductive logic programming, nenro-symbollc reasoning,\\nformal concept analysis, rule-based representations and MIL, uncertainty in ML, of case-based reasoning\\nand analogkcal reasoning), before discussing examples of synergles between KAR and ML, (including\\ntopks such as bellef functions on regression, EM algorithm versus revision, the semantle description of\\nvector representations, the combination of deep learning with high level inference, knowledge graph\\ncompletion, declarative frameworks for data mining, or preferences and recommendation). This paper\\n4s the first step of a work in progress aiming at a better mutual understanding of research in KAR and\\nML, and how they could cooperate.\\n\\n1 Introduction\\n\\nReasoning and learning are two basic concerns at the core of Artificial Intelligence (Al). In the last three\\ndecades, Knowledge Representation and Reasoning (KRR) on the one hand, and Machine Learning (ML)\\non the other hand, have been considerably developed and have specialised themselves in a large number\\nof dedicated sub-fields. These technical developments and specialisations, while they were strengthening\\nthe respective corpora of methods in KRR and in ML, also contributed to an almost complete separation of\\nthe lines of research in these two areas, making many researchers on ane side largely ignorant of what is\\ngoing on, on the other side.\\n\\nThis state of affairs is also somewhat relying on general, overly simplistic, dichotomies that suggest\\nthere exists a large gap between KRR.and ML: KRR deals with knowledge, ML handles data; KRR privileges\\nsymbolic, discrete approaches, while numerical methods dominate ML. Even if such a rough picture points\\nout facts that cannot be fully denied, it is also misleading, as for instance KRR can deal with data as\\nwell [Pral6] (¢.g., in formal concept analysis) and ML approaches may rely on symbolic knowledge (e.g.,\\nin inductive logic programming). Indeed, the frontier between the two fields is actually much blurrier\\nthan it appears, as both are involved in approaches such as Bayesian networks, or case-based reasoning\\nand analogical reasoning, and they share important concems such as uncertainty representation (e.g.,\\nprobabilistic or possibilistic madels, belief functions, imprecise probability-based approaches).\\n\\n \\n\\n‘Kay R. Amel is the pen name of the warking group “Apprentissage et Raisonnement” ofthe GDR (“Granpement De Recherche”)\\nnamed “Aspects Rommels et lgorihuiques de Pinveligence Ariiicidle\", GNRS, Prance (hitpar/werucgdsia fr/presentation/). The\\ncantrfomozs ta this paper include: Zied Bouraoui (CRIL, Lens, Fr, bouraani@eil.f), Antoine Comuéjols (AgmParisTech, Pars Fr,\\namaine.carmejal @agrparistech fr), Thierry Dencemx (Heudiasye, Campigne, Fr, thierydenoenx@ute fr), Sébastien Destercke\\n(Hendizsye, Compigne, Fr, seastien destercke@hds.ute fr), Didier Dubois (IRTT, Tonlonse, Fr, dubois @iri.ft), Ramain Guillaume.\\nORI, Tonlewe, Fr Remain Gullaume@irit.£), Jao Mares-Silva (ANITI, Teulouse, Ms, joao.manues-siva @univconleuse fr),\\néztine Mengin (IRIT, Taulense, Fr, Jerame.Mengin@irit fr), Henri Prade (IRIT, Toulouse, Fr, prade@irit.fr), Steven Schackaert\\n(GGehoel of Computer Science and Infermaties, Cardiff, UK, SehackaertS1 @camiiffae.nk), Mathien Sexrasier (IIT, Tanleuse, Fr,\\nmathien serrurier@ gmail.com), Christel Veain (HIRO, Qxléans,P, Christel Vmain@/univ-orieans.e).']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstract = []\n",
    "\n",
    "cnt = 0\n",
    "while True:\n",
    "    for img in image_jpeg.sequence:\n",
    "        img_page = Image(image=img)\n",
    "        img_page = img_page.make_blob('jpeg')\n",
    "        text = tool.image_to_string(PI.open(io.BytesIO(img_page)),\n",
    "                                   lang=lang,\n",
    "                                   builder=pyocr.builders.TextBuilder())\n",
    "        if \"abstract\" in text.lower():\n",
    "            abstract.append(text)\n",
    "            break\n",
    "    break\n",
    "    \n",
    "abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['These complex madels of preferences have recently been studied from an ML perspective, both in\\nan elicitation / active learning setting, and in a batch / passive learning setting. Que particularity of\\nthese compact preference models is that they combine two elements: a structural element, indicating\\nprobabilistic or preferential interdependencies between the various features characterizing the objects of\\ninterest; and “local” preferences over small combinations of features. I is the structure learning phase\\nwhich is often demanding, since finding the structure that best fits some data is often a hard combinatorial\\nsearch problem. In contrast, finding the local preferences once the structure has been chosen is often easy.\\n\\n‘The passive learning setting is particularly promising because of the vast dataset available in potential\\napplications of preference learning in some decision aid systems like recommender systems or search en-\\ngines. ‘The possibility to learn Bayesian networks fram data has been a key element for their early success in\\nmany applications. Note that in some applications, in particular in the study of biological systems, learning\\nthe structure, that is, the interdependencies between features, is interesting; in such applications, “black-\\nbox” models like deep neural networks seem Jess appropriate. This is also the case in decision-support\\nsystems where there isa need to explain the reasons justifying the computed ordering of passble decisions\\n[BLM*17].\\n\\nAt the frontier between learning and reasaning lies what could be named lazy preference learning:\\ngiven a set of preference statements which do not specify a complete preference relation, one can infer\\nnew pairwise comparisons between objects, by assuming same properties the full, unknown preference\\nrelation. Asa baseline, many settings in the models studied in KRR assume transitivity of preferences, but\\nthis alone does not usually induce many new comparisons. A common additional assumption, made by\\n[BLM+17], is that the preference relation can be represented with an additive utility function, and that\\nthe ordering over the domain of each feature is known. In [Wil06, WilO9, Wil14], richer classes of input\\npreference statements are considered, and the assumption is made that the preference relation has some\\nkind of (unknown) lexicographic structure.\\n\\nLastly, as mentioned above, analogical proportions can be used for predicting preferences [FH18,\\nBPP18, BPPS19]. The general idea is that a preference between two items can be predicted if some analog-\\nical proportions hold that link their descriptions with the descriptions of other items for which preference\\nrelations are known.\\n\\n \\n\\n5 Conclusion\\n\\n‘The KRR and ML areas of AI have been developed independently to a large extent for several decades. It\\nresults that most of the researchers in one area are ignorant of what has been going on in the other area.\\n‘The intended purpase of this joint work is to provide an inventory of the meeting points between KRR and\\nML lines of research. We have first reviewed same concems that are shared by the two areas, maybe in\\ndifferent ways. Then we have surveyed various paradigms that are at the border between KRR and ML.\\nLastly, we have given an overview af different hybridizations of KRR and ML tools.\\n\\nLet us emphasize that this is a work in progress. Subsections may be at this step unequally developed,\\nand remain sketchy. The current list of references is certainly incomplete and unbalanced. The works cov-\\nered may be old or recent, well-known as well as overlooked. However, at this step, we have absolutely\\nno claim of completeness of any kind, not even of being fully up to date. Examples of topics not covered\\nat all are numerous. They include reinforcement learning, argumentation and ML [ASO8], ontology repre-\\nsentation and learning [ASS15], in relation with the modeling of concepts, rough sets and rule extraction\\n[Paw911, GZ00], or formal studies of data such as version space learning [Mit79] or logical analysis of data\\n[BCH*11]; see also [CLL*13, Mirl1].\\n\\nMoreover, each topic covered in this paper is only outlined and would deserve to be discussed in further\\ndetails. This paper is aaly a first step towards a more encompassing and extensive piece of work.\\n\\nThe aim of this paper is to help facilitating the understanding between researchers in the two areas,\\nwith a perspective of cross-fertilisation and mutual benefits. Still we should be aware that the mathematics\\nof ML and the mathematics of KRR are quite different if we consider the main trends in each area. In\\nML the basic paradigm is a matter of approximating functions (which then calls for optimization). The\\nmathematics of MLare close to those of signal pracessing and automatic control (as pointed out in [Le 19]),\\nwhile KRR is dominated by logic and discrete mathematics, leading to an —at least apparent — opposition\\n\\n \\n\\n4']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conclusion = []\n",
    "\n",
    "cnt = len(image_jpeg.sequence)-1\n",
    "\n",
    "while True:\n",
    "    img = image_jpeg.sequence[cnt]\n",
    "    img_page = Image(image=img)\n",
    "    img_page = img_page.make_blob('jpeg')\n",
    "    text = tool.image_to_string(PI.open(io.BytesIO(img_page)),\n",
    "                               lang=lang,\n",
    "                               builder=pyocr.builders.TextBuilder())\n",
    "    if \"conclusion\" in text.lower():\n",
    "        conclusion.append(text)\n",
    "        break\n",
    "    cnt -= 1\n",
    "    \n",
    "conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "from PIL import Image \n",
    "import pytesseract \n",
    "import sys \n",
    "from pdf2image import convert_from_path \n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-e082bbdc49df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# Recognize the text as string in image using pytesserct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpytesseract\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m# The recognized text is stored in variable text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py3/lib/python3.7/site-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36mimage_to_string\u001b[0;34m(image, lang, config, nice, output_type, timeout)\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDICT\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTRING\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m     }[output_type]()\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py3/lib/python3.7/site-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBYTES\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDICT\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTRING\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m     }[output_type]()\n\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py3/lib/python3.7/site-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36mrun_and_get_output\u001b[0;34m(image, extension, lang, config, nice, timeout, return_bytes)\u001b[0m\n\u001b[1;32m    251\u001b[0m         }\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0mrun_tesseract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'output_filename_base'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextsep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py3/lib/python3.7/site-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36mrun_tesseract\u001b[0;34m(input_filename, output_filename_base, extension, lang, config, nice, timeout)\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTesseractNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mtimeout_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror_string\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTesseractError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py3/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py3/lib/python3.7/site-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36mtimeout_manager\u001b[0;34m(proc, seconds)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mseconds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py3/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m                 \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    965\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m                 \u001b[0;31m# https://bugs.python.org/issue25942\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py3/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   1713\u001b[0m                             'failed to raise TimeoutExpired.')\n\u001b[1;32m   1714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1715\u001b[0;31m                     \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1716\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py3/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Path of the pdf \n",
    "PDF_file = \"test.pdf\"\n",
    "  \n",
    "''' \n",
    "Part #1 : Converting PDF to images \n",
    "'''\n",
    "  \n",
    "# Store all the pages of the PDF in a variable \n",
    "pages = convert_from_path(PDF_file, 100) \n",
    "  \n",
    "# Counter to store images of each page of PDF to image \n",
    "image_counter = 1\n",
    "  \n",
    "# Iterate through all the pages stored above \n",
    "for page in pages: \n",
    "  \n",
    "    # Declaring filename for each page of PDF as JPG \n",
    "    # For each page, filename will be: \n",
    "    # PDF page 1 -> page_1.jpg \n",
    "    # PDF page 2 -> page_2.jpg \n",
    "    # PDF page 3 -> page_3.jpg \n",
    "    # .... \n",
    "    # PDF page n -> page_n.jpg \n",
    "    filename = \"page_\"+str(image_counter)+\".jpg\"\n",
    "      \n",
    "    # Save the image of the page in system \n",
    "    page.save(filename, 'JPEG') \n",
    "  \n",
    "    # Increment the counter to update filename \n",
    "    image_counter = image_counter + 1\n",
    "  \n",
    "''' \n",
    "Part #2 - Recognizing text from the images using OCR \n",
    "'''\n",
    "\n",
    "# Variable to get count of total number of pages \n",
    "filelimit = image_counter-1\n",
    "  \n",
    "# Creating a text file to write the output \n",
    "outfile = \"out_text.txt\"\n",
    "  \n",
    "# Open the file in append mode so that  \n",
    "# All contents of all images are added to the same file \n",
    "f = open(outfile, \"a\") \n",
    "  \n",
    "# Iterate from 1 to total number of pages \n",
    "for i in range(1, filelimit + 1): \n",
    "  \n",
    "    # Set filename to recognize text from \n",
    "    # Again, these files will be: \n",
    "    # page_1.jpg \n",
    "    # page_2.jpg \n",
    "    # .... \n",
    "    # page_n.jpg \n",
    "    filename = \"page_\"+str(i)+\".jpg\"\n",
    "          \n",
    "    # Recognize the text as string in image using pytesserct \n",
    "    text = str(((pytesseract.image_to_string(Image.open(filename))))) \n",
    "  \n",
    "    # The recognized text is stored in variable text \n",
    "    # Any string processing may be applied on text \n",
    "    # Here, basic formatting has been done: \n",
    "    # In many PDFs, at line ending, if a word can't \n",
    "    # be written fully, a 'hyphen' is added. \n",
    "    # The rest of the word is written in the next line \n",
    "    # Eg: This is a sample text this word here GeeksF- \n",
    "    # orGeeks is half on first line, remaining on next. \n",
    "    # To remove this, we replace every '-\\n' to ''. \n",
    "    if \"abstract\" in text.lower():\n",
    "        text = text.replace('-\\n', '')     \n",
    "        # Finally, write the processed text to the file. \n",
    "        f.write(text)\n",
    "    if \"conclusion\" in text.lower():\n",
    "        text = text.replace('-\\n', '')     \n",
    "        # Finally, write the processed text to the file. \n",
    "        f.write(text) \n",
    "    \n",
    "  \n",
    "# Close the file after writing all the text. \n",
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
