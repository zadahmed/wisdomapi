{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textract\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = \"test6.pdf\"\n",
    "try:\n",
    "    text = textract.process(pdf)\n",
    "except:\n",
    "    text = textract.process(pdf, method=\"tesseract\", language=\"eng\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.split(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract = []\n",
    "cnt = 0\n",
    "while cnt < len(text):\n",
    "    if \"abstract\" in text[cnt].lower():\n",
    "        if \"abstract\" in text[cnt].lower() and len(text[cnt].split()) < 10:\n",
    "            cnt += 1\n",
    "        while True:\n",
    "            if \"*\" in text[cnt] and len(text[cnt].split()) < 10:\n",
    "                cnt += 1\n",
    "            elif len(text[cnt].split()) > 10:\n",
    "                abstract.append(text[cnt])\n",
    "                cnt +=1\n",
    "            elif len(text[cnt].split()) == 1:\n",
    "                try:\n",
    "                    int(text[cnt])\n",
    "                except:\n",
    "                    break\n",
    "                break\n",
    "            else:\n",
    "                break\n",
    "        break\n",
    "    else:\n",
    "        cnt += 1\n",
    "\n",
    "if not abstract:\n",
    "    stop = 0\n",
    "    while True:\n",
    "        if \"introduction\" in text[stop].lower() and len(text[stop].split()) < 5:\n",
    "            break\n",
    "        else:\n",
    "            stop += 1\n",
    "    cnt = 0\n",
    "    while cnt < stop:\n",
    "        if text[cnt] == \" \" or len(text[cnt]) < 2:\n",
    "            if len(text[cnt+1].split()) < 10:\n",
    "                cnt += 1\n",
    "            else:\n",
    "                abstract.append(text[cnt+1])\n",
    "                if text[cnt+1][-1] == \"-\" or text[cnt+1][:-1] == \"-\":\n",
    "                    while True:\n",
    "                        if text[cnt+2][0].islower():\n",
    "                            abstract.append(text[cnt+2])\n",
    "                            break\n",
    "                        else:\n",
    "                            cnt += 1\n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Gerald A. Mille s, University of Washington, Seattle, WA (Dated: December 18, 2019) Precise knowledge of the nucleon’s axial-current form factors is crucial for modeling GeV-scale neutrino-nucleus interactions. Unfortunately, the axial form factor remains insufficiently constrained to meet the precision requirements of upcoming long-baseline neutrino-oscillation experiments. This work studies these form factors, in particular the axial pseudo-vector elastic form factor, using the light-front approach to build a quark-diquark model of the nucleon with an explicit pion cloud. The light-front wave functions in both the quark and pion-baryon Fock spaces are first calibrated to existing experimental information on the nucleon’s electromagnetic form factors, and then used to predict the axial form factor. We predict the squared charge radius of the axial pseudo-vector form factor to be r3 =0.29+0.03fm?, where the small error accounts for the model’s parametric uncertainty. We use our form factor results to explore the (quasi-)elastic scattering of neutrinos by (nuclei)nucleons. We find the widely-implemented dipole ansatz to be an inadequate approximation of the full form factor for modeling both processes. The approximation leads to a 5—10% overestimation of the total cross section, depending on the (anti)neutrino energy. We project overestimations of neutrino-oscillation experiment.'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstract_string = \"\"\n",
    "\n",
    "for a in abstract:\n",
    "    a = re.sub(\"-\\n\", \"\", a)\n",
    "    a = re.sub(\"\\n\", \" \", a)\n",
    "    if a[-1] not in string.punctuation:\n",
    "        abstract_string += a+\" \"\n",
    "    elif a[-1] == \"-\" or a[-1] == \"-\":\n",
    "        abstract_string += a[:-1]\n",
    "    elif a[-1] in string.punctuation:\n",
    "        abstract_string += a+\" \"\n",
    "\n",
    "if \"abstract\" in abstract_string[:8].lower():\n",
    "    abstract_string = abstract_string[8:]\n",
    "if abstract_string[:1] in string.punctuation or abstract_string[:1] == \"—\":\n",
    "    abstract_string = abstract_string[1:]\n",
    "\n",
    "abstract_string = abstract_string.strip()\n",
    "\n",
    "abstract_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "conclusion = []\n",
    "summary = []\n",
    "cnt = 0\n",
    "while cnt < len(text)-1:\n",
    "    if \"conclusion\" in text[cnt].lower() and len(text[cnt].split()) < 10 or \". Conclusion\" in text[cnt]:\n",
    "        cnt +=1\n",
    "        # cleaning loop\n",
    "        while cnt < len(text)-1:\n",
    "            # if there is text\n",
    "            if len(text[cnt]) > 0:\n",
    "                # if the next sentence is empty\n",
    "                if len(text[cnt+1]) == 0:\n",
    "                    # if 2 ahead is a page number\n",
    "                    if len(text[cnt+2].split()) == 1:\n",
    "                        pass\n",
    "                    elif len(text[cnt].split()) == 1:\n",
    "                        pass\n",
    "                    # if 2 ahead is a title\n",
    "                    elif len(text[cnt+2].split()) < 5:\n",
    "                        conclusion.append(text[cnt])\n",
    "                        break\n",
    "                # if the sentence is not a page number\n",
    "                if len(text[cnt]) > 3:\n",
    "                    #if text[cnt].isupper():\n",
    "                    #    break\n",
    "                    if \"references\" in text[cnt].lower().split()[:5]:\n",
    "                        break\n",
    "                    elif \"acknowledgement\" in text[cnt].lower():\n",
    "                        break\n",
    "                    conclusion.append(text[cnt])\n",
    "            cnt+=1\n",
    "        break\n",
    "    elif \"summary\" in text[cnt].lower() and len(text[cnt].split()) < 10 or \". Summary\" in text[cnt]:\n",
    "        cnt +=1\n",
    "        # cleaning loop\n",
    "        while cnt < len(text)-1:\n",
    "            # if there is text\n",
    "            if len(text[cnt]) > 0:\n",
    "                # if the next sentence is empty\n",
    "                if len(text[cnt+1]) == 0:\n",
    "                    # if 2 ahead is a page number\n",
    "                    if len(text[cnt+2].split()) == 1:\n",
    "                        pass\n",
    "                    elif len(text[cnt].split()) == 1:\n",
    "                        pass\n",
    "                    # if 2 ahead is a title\n",
    "                    elif len(text[cnt+2].split()) < 5:\n",
    "                        conclusion.append(text[cnt])\n",
    "                        break\n",
    "                # if the sentence is not a page number\n",
    "                if len(text[cnt]) > 3:\n",
    "                    #if text[cnt].isupper():\n",
    "                    #    break\n",
    "                    if \"references\" in text[cnt].lower().split()[:5]:\n",
    "                        break\n",
    "                    elif \"acknowledgement\" in text[cnt].lower():\n",
    "                        break\n",
    "                    conclusion.append(text[cnt])\n",
    "            cnt+=1\n",
    "        break\n",
    "    else:\n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In this work, the light-front quark model with pion\\ncloud is employed to correlate the nucleon’s EM form fac-\\ntors with its axial form factors. The model is calibrated\\nto the EM form factors’ measurements, and then used to\\npredict the axial form factor F,y. We found our form\\nfactor’s r, = 0.29 + 0.03fm?; its central value is smaller\\nthan the one resulted from a rec‘ s [5] neutrino-\\nnucleon scattering data and the singlet muonic hydrogen\\ncapture rate measurement, r?, = 0.46-£0.16fm?, although\\nthey are still consistent within 1-o error bar. Meanwhile,',\n",
       " '  \\n \\n  \\n ',\n",
       " 'Differential cross section for anti-neutrino scattering',\n",
       " 'at E, = 0.5 and 2 GeV. See the caption of Fi',\n",
       " 'our value is closer to the current Lattice QCD results\\nfrom 0.2 — 0.45fm?, although these Lattice calculations\\nstill have room to be improved []. Note the correspond-\\ning M4 = 1.28-0.07 MeV (based on the form factor’s Q?\\nderivative at zero) is larger than M4 = 1.01 + 0.17GeV?',\n",
       " 'from Ref. [5] [I7]).',\n",
       " 'More importantly, we found the widely used dipole\\ntimates the',\n",
       " 'approximation to our full Fyy  over-\\n(anti)neutrino scattering cross sections, as compared to\\nthe calculation using the full expression, by about 5%\\nat neutrino energy around 0.5 GeV and reaches about\\n10% at 10 GeV. By using the GiBUU simulation pack-',\n",
       " ' \\n\\x0c16',\n",
       " '    \\n ',\n",
       " '14\\n10\\n12\\n~ 10 S08\\n% 6\\n2 os 2 06\\n® °\\n2 0.6 S04\\nSod Gp(M4=1.28) .\\nbo Goes 02\\n00 iD(M4=1) 0.0\\n1.20 11s\\n. ig 1.10\\n3 = 1.05\\n& =~ 1.00\\nfee 0.95',\n",
       " 'E,(GeV)',\n",
       " 'FIG. 9.',\n",
       " 'Total cross section for CC-induced neutrino and antineutrino scattering off nucleon.',\n",
       " 'E,(GeV)',\n",
       " 'In the upper panels, three',\n",
       " 'different calculations are plotted with different axial form factor, while the lower panels show the ratios between the results\\nusing the full Fiy and the one using ga@p and M4 = 1.28 GeV (red dotted curve) and with the results using gaGp and',\n",
       " 'Ma = 1 GeV.',\n",
       " '0.00030\\n0.00025,\\n0.00020\\n0.00015,\\n0.00010\\n0.00005,\\n0.00000',\n",
       " 'Flux',\n",
       " '0 1 2 3 4 5 6 7\\nEy(GeV)\\nFIG. 10. .',\n",
       " 'mode in the DUNE experiment’s near detector\\nunits are irrelevant in this work.',\n",
       " 'The v,, and 7, fluxes in neutrino and antineutrino',\n",
       " '   \\n ',\n",
       " 'age, we studied how this epancy could impact the\\n(anti)neutrino QE cross sections (without short-range-\\ncorrelation’s contribution and pion production mecha-\\nnisms) for the coming DUNE experiment. The flux-\\naveraged differential cross section vs Q? could get over-\\nestimated by 5% at the Q? ~ 0.2GeV? and reaches\\naround 10% at 1GeV?. The difference between the over-\\nestimation in the neutrino scattering and that in the an-\\ntineutrino scattering increases to a few percent level when\\nQ? goes above 0.5GeV”, which could be relevant for the\\nneutrino-oscillation measurements interested in the dif-\\nference between neutrino and antineutrino.',\n",
       " 'In the current work for simplicity, we don’t use the\\nexperimental EM form factor data sets, but instead the\\nresults of the data analysis (based on the z-expansion)\\nfrom Ref. [£7]. For simplicity, the correlations between',\n",
       " 'their extracted form factors—not available in public—\\nare ignored in our model calibration. In the future work,\\ncither directly using the experimental data or including\\nthe correlation in the results from [47] will improve our\\ncalibration of the model. Moreover, the theoretical un-\\ncertainty of our quark model is not fully explored, even\\nthough we have used a somewhat flexible parametrization\\nof the quark-diquark wave functions.',\n",
       " 'In the pion-cloud calculation, the A resonance’s con-\\ntribution is computed by using its form factors either\\nfrom Lattice QCD calculations or experimental measure-\\nments. However a more consistent approach is to base\\nthe inelastic form factor used in the pion-cloud calcula-\\ntions on the A’s light-front wave functions. This will also\\nallow studying the axial inelastic form factors, which are\\nalso poorly constrained but important for understanding\\nthe pion productions in the coming neutrino experiments,\\nwithin the same framework.',\n",
       " 'ACKNOWLEDGMENTS',\n",
       " 'X.Z. was supported by the US Department of Energy\\nunder contract DE-FG02-97ER-41014, the US Institute\\nfor Nuclear Theory, and the National Science Foundation\\nunder Grant No. PHY1614460 and the NUCLEI SciDAC\\nCollaboration under US Department of Energy MSU sub-\\ncontract RC107839-OSU. T.H. was supported by the US\\nDepartment of Energy under contract de-sc0010129) and\\nalso acknowledges support from a JLab EIC Center Fel-\\nlowship. G.M. was supported by the US Department of\\nEnergy under contract DE-FG02-97ER-41014. XZ would\\nlike to thank Urich Mosel for his help with running the\\nGiBUU package.',\n",
       " '  \\n\\x0c17',\n",
       " ' \\n \\n    ',\n",
       " 'Ay —\\nGp (My=1.28)\\nGp(My=1) ~~~',\n",
       " 'do dQ? /A(10~38 cm? GeV?)',\n",
       " '(a) |',\n",
       " ' \\n      ',\n",
       " '. Fin\\nGp(My=1.28)',\n",
       " 'do dQ? /A(10-38 cm? GeV-2)',\n",
       " '0.2 01\\n0.0 4 0.0\\n0.0 0.5 1.0 15 2.0 0.0 0.5 1.0 1.5 2.0\\n(GeV?) (GeV?)\\n1.00\\n0.95\\n2\\n3\\n~ 0.90\\n0.85',\n",
       " '0.0 0.5',\n",
       " 'FIG. 11.',\n",
       " 'The DUNE-fiux averaged v(7)-*°Ar scattering differential cr',\n",
       " 'ion. The lower panel again shows the ratio',\n",
       " 'between the result using our model form factor and the one using its dipole approximation with Ma = 1.28 GeV.',\n",
       " 'dw\\nda =3\\n=7 vi (My +\") +2Myyi gi\\nT 5 VERE > (Mw\\n3 pi gi (My +',\n",
       " 'TABLE IV. 6,8 /V for quark scalar diquark configuration',\n",
       " 'Appendix A: quark wave functions',\n",
       " 'The scalar-diquark wave functions have already been\\ncomputed in Ref. [30], but we present them here for\\nthe sake of completeness. We note that the notation\\nused here is somewhat different from that in Ref. [30].\\nOur choices for the metric and Dirac spinors follow the\\nLepage-Brodsky conventions in Ref. 24]. The expres-\\nsion for the bare-quark form factors (cf. Eqs. (14), (15),\\nand (I6)) in terms of the quark light-front wave Function,\\nare',\n",
       " ' \\n\\x0c18',\n",
       " 'Aw\\nAaa -3 4\\n=-t ttt 0\\n=3,0_ ef — Ste (My — 48) -ee\\n=e ptv2(Mn + ™)\\n—pt V2(My +) es\\nie — ois + vite (Ws — 38)',\n",
       " 'TABLE V. 6,\\\\, /V for quark axial diquark configuration',\n",
       " 'gi [omg +aMy) +k',\n",
       " 'fa = [ Mae\\nas | 80',\n",
       " \"fas = / T6r' : {ei\\n+ (%' vit os e) 2x My (mq +eMy) + 9% pda? Ma}\",\n",
       " 'f= fcapieatmay OA [(-GPee) Sat apt mm tm',\n",
       " '5’ 8 sos 8! 8 ki-g\\n{ot gi (mg + eMy) (1-2) + (vf pit es gi) a(1—a)My + (of $2 - 3 gi) 2x My 77 +\\n(1',\n",
       " 'gi vi [om +aMy) — ki + Coq',\n",
       " ', 2am? me\\n+ (of 8 + of ot) Toa iy (4 PMS) + 8 eT [ime ~ aM)\" + \" -\\n()Mydrdbes { aa yal a) 2M alg\\nfra = fF Ted 2) 1 pte (mg +xMy) + (vf 92 +95 vi) Te + 2 Plage arg a1 ) (mq — eMy)\\ndedk (l=2)? 9) 1+? oat m2 2\\n= ot - — aM,\\nfae fae os al(a O) Tae Ta aye at)\\na 2am? Ma (l= 2)?\\n+ (of v8 +8 gf) W-aik (mq —2My) + py rae [ima = 1 Nel }',\n",
       " 'Note the expressions in these form factor involving ¢§ are different, as well as the yf’ y$. The former is because\\nwe use a different wave function for 3, while the latter is because we use < instead of ¢ in defining wave functions\\ninvolving axial diquark (cf. discussion in n\\'Sec. [IT B}. To simplify the presentation, the quark wave functions’ dependence\\non the integration variables are implicit: pile, kit) and yj = yi(x,ky.) with k k, — 45\"q. and\\nkp =k. +452q.. Here the integration variable k, is shifted from the k, in Eqs. 1. In these\\nexpressions, mg, ms, and ma are the masses of the quark, scalar and axial-vector diquarks.',\n",
       " '     ',\n",
       " '        ',\n",
       " 'Appendix B: Hadronic interaction and electroweak _ spinors:\\ncurrent matrix elements',\n",
       " ') =enctn (5) (31)\\n) - [pen (-3) + enor ( )\\n) = penn (-3) + [fon ( )\\nJ=scam()',\n",
       " '    ',\n",
       " 'The results for NV — N — m interaction verti\\nfound in Table [VI] The assignment of intrinsic kinetic Up\\nvariables has been discussed in Sec. The met-\\nric and Dirac spinor convention used again follows the (',\n",
       " 'u, (-',\n",
       " 'NIE WIE',\n",
       " 'Lepage-Brodsky in Ref. [2d].',\n",
       " 'To calculate matrices elements for N — A — 7 interac- -\\ntion, we need a convention for spin-3/2 Rarita-Schwinger',\n",
       " '| + (ef e+ 98 el) ey (mg + eM) + 98 ose ug}',\n",
       " '(ai)\\n} an',\n",
       " '(A3)',\n",
       " '(A4)',\n",
       " '(A6)\\n\\x0c ',\n",
       " 'Aw Aw\\ndw =3 z =3\\niMy(—@ iWaK® ze a\\n=3 ae ) —HGe = [FE (My — Ma) + FM, (My + Ma)]\\niv 3k My (@—1) 7 SEO\\n3 2k iMy(e=1) Sate Fix — Fit) Ma + 2F 64 (Mn — Ma)]',\n",
       " '[Fe Ma (Mx —Ma)—F RM, Ma (My +Ma)+4F0.4\"\")\\nTE\\nCeres + PM)',\n",
       " 'TABLE VL Vr pd using helicity _ basis. Note',\n",
       " 'wy wi\\n(@, B® RY) = —Vay dy, (@,—K*, RY). Changing\\nthe sign of k* leads to k” 4 k®. This property can be used\\nto infer the matrix elements with positive 4,,, based on given TABLE VII.\\nmatrix elements with negative ,,,',\n",
       " 'Vary pad',\n",
       " '(a) =\\nta (Py sAa PSX ,a (GPx iP )U(Px Aw yee) using —helic-\\nity basis. Note TQ ay (Q(q\".a\") = IO. (a)(-4\", 4\")\\ns to q’ + q®. This property\\nan be used to infer the matrix elements with positive ,,\\nbased on given matrix elements with negative A,',\n",
       " '     ',\n",
       " '    ',\n",
       " 'ia 3/?E® (Ma + Myx)',\n",
       " '  \\n ',\n",
       " '[2k’k® — (Mya —2Ma)(Ma + Myz)]',\n",
       " '2 (KE)?',\n",
       " 'TABLE VII Va, using helicity basis. Note\\nVing ory (tk bY) = Vay dy (t,-k*, bY). Changing the\\nsign of k® leads to k* 4 Ke. This property can be used to\\ninfer the matrix elements with positive \\\\y based on given\\nmatrix elements with negative A,,.',\n",
       " '  \\n \\n ',\n",
       " 'Here the spin projec ions are labeled\\nas the numbers in parenthesis. Note the vector ,, is dif-\\nferent from the one used in axial-diquark wave function:\\nit satisfies pc, = 0 [29]. The results are collected in\\nTable [VII] To compute the current matrix elements, we\\nalways choose a frame with g* = 0. The results in Ta- 3',\n",
       " '$+C#)My]\\n(ce Mx (My + Ma) — 2C3\\\\q\"q\" My — C}Ma q\"\\'q\"]\\n[(C#Ma(Ma + My) + 2(C3\\' — C#)MR)]',\n",
       " 'Poa\\n2 VeMaNy',\n",
       " 'bles [VILIIX] [X] and [XIJare of course boost and rotation 3 _@Y oa\\ninvariant (in the transverse plane). To reduce space for 2 viMg *',\n",
       " 'presentations, only subset of the matrix elements men-',\n",
       " 'tioned here are shown, while the others can be inferred TABLE IX. FOX, (a) =',\n",
       " 'using the mirror transformation (w.r-t. to the y-z plane) a. (p, .)P%4 .(q.pyiPa)ulPyAx)/C@pt) using helic-',\n",
       " 'of these elements (i.e., parity transformation multiplied ty b Not 74 (@(a\",@\") = In rm (',\n",
       " 'by proper rotation). See the captions of the tables for WY P&S! Nofe Joa, ay (Ord D(-4a\".4\") «',\n",
       " 'the details. Changing the sign of q” leads to q! © g. This property can\\nbe used to infer the matrix elements with positive \\\\, based\\non given matrix elements with negative \\\\,,',\n",
       " ' \\n\\x0c20',\n",
       " '=z\\na (MR BFia—4Foa)4+ Fan —Fialana™)\\navoM3',\n",
       " '1 a” (MR (8Fia 4F2a) H2P2a—Fia)a\" a\") (Past Pala yp. 4 (Pa Falla) (e)',\n",
       " '2 AVE Mg ta + omg',\n",
       " '1 (a)? (MR Pea —4Poa)— Fang’ a®) a” (SMA (Poa —2Fa)+M3 (Poa —4Paa + Fina\" a\" 42Faa a\") (4\")\")\\n3 “oe Ss eee a -',\n",
       " '2 aVIME',\n",
       " 'Fiadea®)\\nAVSMT,',\n",
       " 'TABLE X. J using helicity basis. Note JP\". (g*,q”) = Fi\" (—q\",q\"). Changing the sign of g® leads to q” 4 q®.\\naka 1 a\\nThis property can be used to infer the matrix elements with positive A, based on given matrix elements.',\n",
       " '(Fag -8Fia)aa® gp 2Faa(a*)\"(a\")\\n3 (feast 4p, — Aa PO\\n1\\nz AVM 0\\n3 Faa (a)\\na 0 :',\n",
       " '(—q\".q\"). Changing the sign of g® leads to\\na A\\nq” + q®. This property can be used to infer the matrix elements with positive A, based on given matrix elements',\n",
       " ' \\n\\x0c ',\n",
       " \"POUGIA®POS ADs |\\nPRO NODS COS COD 's |\",\n",
       " 'KSA AAR SSIS.',\n",
       " '<< JOB\\n—@ 40\\n“PBI a\\n_ABBABBKE a\\n— CVIVSPS on\\n@SIeysse9 iL\\n~“FBBVIAVUS a\\n— 2468 T96H ADE HH\\nADI AADBALOD £1 7',\n",
       " ' \\n\\x0c[1] S. Ritz et al. (HEPAP Subcommittee),',\n",
       " '   \\n \\n ',\n",
       " '(2014).',\n",
       " '[2] L. Alvarez-Rus .,{Prog. Part. Nucl. Phys. 100, 1) [22\\n(2018)| jarXiv:1706.03621 [hep-ph] 23 . .\\n[3] J. A. Formaggio and G. P. Zeller, Rev. Mod. Phys. 84, Lett. B357, 267 (1995) oe nucl-th]\\n1307 (2012)| arXiv:1305.7513 [hep-ex| [24] 8. J. Brodsky, H. CP and S. S. Pinsky,|Phys. Rept.\\n301, 299 (1998)] {a',\n",
       " '4) V. Bernard, L. Elouadrhiri, and U.-G. Meissner,|J. Phys\\nG28, R1 (2002), /arXiv:hep-ph/0107088 [hep-ph|',\n",
       " '        ',\n",
       " '| R. J. Hill, P. Kammel, W. J. Marciano, and A. Sirlin,',\n",
       " 'vs.\\nth/0207007 {muck thy)',\n",
       " ' \\n  ',\n",
       " '° ape Prog. Phys. 81, 096301 (2018)] farXiv:1708.08462, [26] G. A. Miller and M. R. Frank, Phys. Rev. C65, 065205\\nhep-pl (2002) farKivinnel-th (0201021 [nucl-th\\nZronfeld, D. G. Richards, W. Detmold, R. Gupta, 27] B-Q. Ma, D. Qing, and I. Schmidt, Phys. Rev. C65,\\nH-W. Lin, K-F. Liu, A. S. Meyer, R. Sufian, and 035205 (2002)] jarXiv:hep-ph/0202015 [hep-ph]\\nS. Syritsin (USQCD), (2019), jarXiv:1904.09931 [hep-| [28] B-Q. Ma, D. Qing, and I. Schmidt, Phys. Rev. C66,\\nlat] 048201 (2002)] jarXiv:hep-ph/0204082 [hep-ph]\\n3reen, N. Hasan, S. Meinel, M. Engelhardt, S. Krieg, [29] B. Pasquini and 8. Boffi,\\nLaeuchli, J. Negele, K. Orginos, A. Pochinsky, 289\\naa S. Syritsyn, [Phys. Rev. D95, 114502 (2017), [30] IL. C. Cloet and G. A. Miller, /Phys.Rev.C 86, 015208\\nlarXiv:1703.06703 [hep-lat]) (2012)] jarXiv:1204,4422 [nucl-th\\n[8] R. Gupta, Y-C. Jang, H.-W. Lin, B. Yoon, and — [81] V. Punjabi, C. F. Perdrisat, M. K. Jones, E. J. Brash,\\nT. Bhattacharya, [Phys. Rev. D96, 114503 (2017) and C. E. Carlson, [Eur. Phys. J. A51, 79 (2015',\n",
       " 'arXiv:1705.06834 [hep-lat',\n",
       " '[9] S. Capitani, M. Della Morte, D. Djukanovic, G. M. von\\nHippel, J. Hua, B. Jger, P. M. Junnarkar, H. B, Meyer,',\n",
       " '     ',\n",
       " 'arXiv:1503.01452 [nucl-ex\\nS. J. Brodsky, G. F. de Teramond, H. G. Dosch, and\\nJ. Erlich, /Phys. Rept. 584, 1 (2015)| arXiv:1407.8131',\n",
       " 'T. D. Rae, and H Wittig, nt. Mod. Phys. A34,',\n",
       " '   \\n   \\n ',\n",
       " '  \\n   ',\n",
       " '1950009 ( (2019)',\n",
       " '~ : . Gupta, H.-W. Lin, and\\nB. Yoon, Proceedings 35th International Symposium on\\nLattice Field srneory (Lattice 2017): Granada, Spain,',\n",
       " '(hep-ph|\\n‘A.W. Thomas, 8. Theberge,',\n",
       " 'Rev. D24, 216 (1981\\nO. Buss, T. Gaitanos, K. Gallmeister, H. van Hees,\\nM. Kaskulov, O. Lalakulich, A. B. Larionov, T. Leit-',\n",
       " 'and G. A. Miller, Phys.',\n",
       " '     ',\n",
       " '    ',\n",
       " 'ner, J. Weil, and U. Mosel, Phys. Rept. 512, 1 (2012)\\narXiv:1106.1344 [hep-ph]\\niu) , Y. Kuramashi, S. Sasaki, N. Tsukamoto, [35] R. Acciarri_ef al. E), (2015), /arXiv:1512.06148)\\nA. Ukawa, and T. Yamazaki (PACS), Phys. Rev. D98, [physics.ins-det]\\n074510 (2018)| jarXiv:1807.03974 [hep-lat] 36] H. Meyer and P. J. Mulders, Nucl. Phys. A528, 589\\n(12) G. 8. Bali, S.Collins, M. Gruber, A. Schfer, [ (1991)\\nP. Wein, and T. Wurm, Phys. Lett. B789, 666 (2019), [37] S. J. Brodsky, J. R. Hiller, D. S. Hwang, and V. A.\\niv:1810. Karmanoy, Phys. Rev. D69, 076001 (2004)| /arXiv:hep-\\n{13] E. Shintani, K.-I. Ishikawa, Y. Kuramashi, S. Sasaki, ph/0311218 [hep-ph]\\nand T. Yamazaki, . Rev. D99, 014510 (2019) 38] T.-M. Yan, Phys. Rev. D7, 1780 (1973)\\narXiv:1811.07292 [hep- 39] S. Weinberg. quantum theory of fields. Vol. 2: Mod-\\n[14] S, hattacharya, R. Gupta, H.-W. Lin, ern applications (Cambridge University Press, 2013)',\n",
       " 'and B. Yoon (PNDME), Proceedings, 36th International\\nSymposium on Lattice Field Theory (Lattice 2018): East',\n",
       " '      ',\n",
       " 'B. D. Serot and X. Zhang, |Phys. Rev.',\n",
       " 'C86, 015501',\n",
       " '(2012)) arXiv:1206.3812 [nucl-th],',\n",
       " 'Lansing, MI, United States, July 22-28, 2018, PoS LAT-',\n",
       " 'V. Pascalutsa, M. Vanderhaeghen, and S. N. Yang, Phy\\na',\n",
       " 'TICE2018, 123 (2018), arXiv: 1901 00060 [hep-lat Rept. 437, 125 (2007)| arXiv:hep-ph/0609004 [hep',\n",
       " \"5] J. J. Kelly, Phys 5; [22] 'T. Leitner, O. Buss, L. Alvarez-Ruso, and U. Mosel,\",\n",
       " '[16] B. Bhattacharya, R. J. Hill, and G Par Ph Rev. Phys. Rev. C79, 034601 (2009)| jarXiv:0812.0587 [nucl-\\nD84, 073006 (2011)] /arXiv:1108.0423 [hep-ph] th',\n",
       " '[17] A. S. Meyer, M. Betancourt, R. Gran, and R. J. Hill, [43] C. Alexandrou, E. B. Gregory, T. Korzec, G. Koutsou,\\nhys. Rev. D93, 113015 (2016), /arXiv:1603.03048 [hep- J. W. Negele, T. Sato, and A. Tsapalis,/Phys. Rev. D87,',\n",
       " 'phi)',\n",
       " 'C. Perdrisat, V. Punjabi, and M. Vanderhaeghen,',\n",
       " '114513 (2013) farXiv:1304.4614 [hep-lat]',\n",
       " 'H. H. Matevosyan, G. A. Miller, and A. W. Thomas,',\n",
       " 'Prog.Part.NuclPhys. 59, 694 (2007)|_[arXiv:hep-',\n",
       " '(2005)| jarXiv:nucl-th/0501044',\n",
       " 'ph/0612014 [hep-ph\\n19] S. Pacetti, R. Baldini Ferroli, and E. Tomasi-Gustafsson,\\n[Phys. Rept. 550-551, 1 (2015)\\nM. R. Schindler and S. Scherer, Proceedings, 3rd Inter-\\nnational Workshop on From parity violation to hadronic\\nstructure and more (PAVI 2006): Milos, Greece, May\\n16-20, 2006, Eur. Phys. J. A82, 429 (2007 (2006)],\\nlarXiv:hep-ph',\n",
       " '  \\n ',\n",
       " '    \\n    ',\n",
       " 'Phys. Rev. C71, 055204 (2005)| arXiv:\\nnucl-th]\\n5] L. Tiator, D. Drechsel, S. S. Kamalov,',\n",
       " 'B] C. oe T. Korzec, G.',\n",
       " ' \\n   ',\n",
       " 'and M. Van-',\n",
       " 'derhaeghen, ST 198, 141 (2011',\n",
       " '   \\n ',\n",
       " '     ',\n",
       " 'Koutsou, T. Leontiou,\\nC. Lorce, J. W. Negele, V. Pascalutsa, A. Tsapalis,\\nand M. Vanderhaeghen, Phys. Rev. D79, 014507 (2009)\\narXiv:0810.3976 [hep-lat,',\n",
       " 'S. Scherer, Nucl. 64, 1',\n",
       " 'Prog. Part.',\n",
       " 'Phys. (2010)',\n",
       " 'Z. Ye, J. Arrington, R. J. Hill, and G. Lee, Phys. Lett.',\n",
       " ' \\n\\x0c23',\n",
       " '[_B777, 8 2018)] jarXiv:1707.09063 [nucl-ex] [50] W. D. Vousden, W. M. Farr, and I. Mandel, MNRAS|',\n",
       " '[48] D. Sivia, Data Analysis: A Bayesian Tutorial (Oxford 455, 1919 (2016)| arXiv:1501.05823 [astro-ph.IM]\\nUniversity Press, New York, 1996). [51] C. H. Llewellyn Smith, Gauge Theories and Neutrino',\n",
       " '[49] D. Foreman-Mackey, D. W. Hogg,',\n",
       " '   \\n  ']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The KRR and ML areas of AI have been developed independently to a large extent for several decades. It results that most of the researchers in one area are ignorant of what has been going on in the other area. The intended purpose of this joint work is to provide an inventory of the meeting points between KRR and ML lines of research. We have first reviewed some concerns that are shared by the two areas, maybe in different ways. Then we have surveyed various paradigms that are at the border between KRR and ML. Lastly, we have given an overview of different hybridizations of KRR and ML tools. Let us emphasize that this is a work in progress. Subsections may be at this step unequally developed, and remain sketchy. The current list of references is certainly incomplete and unbalanced. The works covered may be old or recent, well-known as well as overlooked. However, at this step, we have absolutely no claim of completeness of any kind, not even of being fully up to date. Examples of topics not covered at all are numerous. They include reinforcement learning, argumentation and ML [AS08], ontology representation and learning [ASS15], in relation with the modeling of concepts, rough sets and rule extraction [Paw91, GZ00], or formal studies of data such as version space learning [Mit79] or logical analysis of data [BCH+ 11]; see also [CLL+ 13, Mir11]. Moreover, each topic covered in this paper is only outlined and would deserve to be discussed in further details. This paper is only a first step towards a more encompassing and extensive piece of work. The aim of this paper is to help facilitating the understanding between researchers in the two areas, with a perspective of cross-fertilisation and mutual benefits. Still we should be aware that the mathematics of ML and the mathematics of KRR are quite different if we consider the main trends in each area. In ML the basic paradigm is a matter of approximating functions (which then calls for optimization). The mathematics of ML are close to those of signal processing and automatic control (as pointed out in [Le 19]), while KRR is dominated by logic and discrete mathematics, leading to an – at least apparent – opposition 24 between geometry and logic [Mal18]3 . But functions also underlie KRR, once one notices that a set of (fuzzy or weighted) rules is like an aggregation function [DP97], whose computation may take the form of a generalized matrix calculus (‘generalized’ in the sense that the operations are not necessarily restricted to sum and product). Let us also note that the convolution of functions (a key tool in signal processing) is no longer restricted to a linear, sum/product-based setting [MP19]. Besides, it seems difficult to envisage ML without KRR. For instance, it has been recently observed that • the unsupervised learning of disentangled representations is fundamentally impossible without inductive biases on both the models and the data [LBL+ 18]; • local explanation methods for deep neural networks lack sensitivity to parameter values [AGGK18]; • when trained on one task, then trained on a second task, many machine learning models “forget” how to perform the first task [GMD+ 14]. Such states of fact might call for some cooperation in the long range between ML and KRR.'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conclusion_string = \"\"\n",
    "\n",
    "for c in conclusion:\n",
    "    c = re.sub(\"-\\n\", \"\", c)\n",
    "    c = re.sub(\"\\n\", \" \", c)\n",
    "    if \"\\x0c\" in c:\n",
    "        text = c.split(\"\\x0c\")[1:]\n",
    "        text = \" \".join(t for t in text)\n",
    "        conclusion_string += text+\" \"\n",
    "    elif c[-1] not in string.punctuation:\n",
    "        conclusion_string += c+\" \"\n",
    "    elif c[-1] == \"-\" or c[-1] == \"-\":\n",
    "        conclusion_string += c[:-1]\n",
    "    elif c[-1] in string.punctuation:\n",
    "        conclusion_string += c+\" \"\n",
    "        \n",
    "# filter out sentences that have 'Figure' in them\n",
    "conclusion_string2 = re.sub(\"Figure\", \".|$|\", conclusion_string)\n",
    "conclusion_string2 = re.sub(\"Fig.\", \".|$|\", conclusion_string2)\n",
    "conclusion_string2 = re.sub(\"Fig\", \".|$|\", conclusion_string2)\n",
    "conclusion_string2 = re.sub(\"\\d[.]\", \"\", conclusion_string2)\n",
    "conclusion_string2 = conclusion_string2.split(\".|\")\n",
    "\n",
    "conclusion_string_final = \"\"\n",
    "\n",
    "for c in conclusion_string2:\n",
    "    if \"$|\" in c:\n",
    "        if \". \" in c:\n",
    "            text = c.split(\". \")\n",
    "            if text[1][0].islower():\n",
    "                new_text = \". \".join(t for t in text[1:]).strip()\n",
    "                conclusion_string_final += new_text+\" \"\n",
    "        else:\n",
    "            pass\n",
    "    else:\n",
    "        conclusion_string_final += c\n",
    "\n",
    "conclusion_string_final = conclusion_string_final.strip()\n",
    "conclusion_string_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
