{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import io\n",
    "import string\n",
    "from PyPDF2 import PdfFileReader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get PDF text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfurl = \"http://arxiv.org/pdf/1811.04422v1\"\n",
    "r = requests.get(pdfurl, stream=True)\n",
    "f = io.BytesIO(r.content)\n",
    "reader = PdfFileReader(f)\n",
    "\n",
    "# Get text\n",
    "text = \"\"\n",
    "page = 0\n",
    "while True:\n",
    "    try:\n",
    "        content = reader.getPage(page).extractText()\n",
    "        text += content\n",
    "        page += 1\n",
    "    except:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.split(\"\\n\\n\")\n",
    "\n",
    "# collect abstract text\n",
    "abstract = []\n",
    "cnt = 0\n",
    "\n",
    "if \"\\n \\n\" in \" \".join(i for i in text):\n",
    "    content = []\n",
    "    for i in text:\n",
    "        for j in i.split(\"\\n \\n\"):\n",
    "            content.append(re.sub(\"\\n\", \"\", j))\n",
    "    while cnt < len(content):\n",
    "        if \"abstract\" in content[cnt].lower():\n",
    "            if \"abstract\" in content[cnt].lower() and len(text[cnt].split()) < 10:\n",
    "                cnt += 1\n",
    "            while True:\n",
    "                if \"introduction\" in content[cnt].lower():\n",
    "                    break\n",
    "                abstract.append(content[cnt])\n",
    "                cnt += 1\n",
    "            break\n",
    "        else:\n",
    "            cnt += 1\n",
    "else:\n",
    "    while cnt < len(text):\n",
    "        if \"abstract\" in text[cnt].lower():\n",
    "            if \"abstract\" in text[cnt].lower() and len(text[cnt].split()) < 10:\n",
    "                cnt += 1\n",
    "            while True:\n",
    "                if \"*\" in text[cnt] and len(text[cnt].split()) < 10:\n",
    "                    cnt += 1\n",
    "                elif len(text[cnt].split()) > 10:\n",
    "                    if \"introduction\" in text[cnt][:20].lower() or \"i ntroduction\" in text[cnt][:20].lower():\n",
    "                        break\n",
    "                    abstract.append(text[cnt])\n",
    "                    cnt +=1\n",
    "                elif len(text[cnt].split()) == 1:\n",
    "                    try:\n",
    "                        int(text[cnt])\n",
    "                    except:\n",
    "                        break\n",
    "                    break\n",
    "                else:\n",
    "                    break\n",
    "            break\n",
    "        else:\n",
    "            cnt += 1\n",
    "    if not abstract:\n",
    "        stop = 0\n",
    "        while True:\n",
    "            if \"introduction\" in text[stop].lower() and len(text[stop].split()) < 5:\n",
    "                break\n",
    "            else:\n",
    "                stop += 1\n",
    "        cnt = 0\n",
    "        while cnt < stop:\n",
    "            if text[cnt] == \" \" or len(text[cnt]) < 2:\n",
    "                if len(text[cnt+1].split()) < 10:\n",
    "                    cnt += 1\n",
    "                else:\n",
    "                    abstract.append(text[cnt+1])\n",
    "                    if text[cnt+1][-1] == \"-\" or text[cnt+1][:-1] == \"-\":\n",
    "                        while True:\n",
    "                            if text[cnt+2][0].islower():\n",
    "                                abstract.append(text[cnt+2])\n",
    "                                break\n",
    "                            else:\n",
    "                                cnt += 1\n",
    "            cnt += 1\n",
    "            \n",
    "# format abstract to present to user\n",
    "abstract_string = \"\"\n",
    "for a in abstract:\n",
    "    a = a.strip()\n",
    "    a = re.sub(\"-\\n\", \"\", a)\n",
    "    a = re.sub(\"\\n\", \" \", a)\n",
    "    if a[-1] not in string.punctuation:\n",
    "        abstract_string += a+\" \"\n",
    "    elif a[-1] == \"-\" or a[-1] == \"-\":\n",
    "        abstract_string += a[:-1]\n",
    "    elif a[-1] in string.punctuation:\n",
    "        abstract_string += a+\" \"\n",
    "# remove word 'abstract' and date at start\n",
    "if \"abstract\" in abstract_string[:8].lower():\n",
    "    abstract_string = abstract_string[8:]\n",
    "dummy1 = abstract_string.split(\". \")\n",
    "dummy2 = abstract_string.split()\n",
    "if \"abstract\" in dummy1[0].lower():\n",
    "    print(dummy1[0])\n",
    "    cnt = 0\n",
    "    while True:\n",
    "        if dummy2[cnt].lower().strip() != \"abstract\":\n",
    "            cnt += 1\n",
    "        else:\n",
    "            cnt += 1\n",
    "            break\n",
    "    abstract_string = \" \".join(word for word in dummy2[cnt:])\n",
    "if abstract_string[:1] in string.punctuation or abstract_string[:1] == \"—\":\n",
    "    abstract_string = abstract_string[1:]\n",
    "abstract_string = abstract_string.strip()\n",
    "print(\"Abstract:\\n\\n\", abstract_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abstractapi import abstractextracter\n",
    "import gensim\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I describe an optimal control view of adversarial machine learning, where the dynamical system is the machine learner, the input are adversarial actions, and the control costs are defined by the adversary’s goals to do harm and be hard to detect. This view encompasses many types of adversarial machine learning, including test-item attacks, training-data poisoning, and adversarial reward shaping. The view encourages adversarial machine learning researcher to utilize advances in control theory and reinforcement learning.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstractextracter(\"http://arxiv.org/pdf/1811.04422v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfFileReader\n",
    "from pathlib import Path\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137564"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdfurl = \"http://arxiv.org/pdf/1811.04422v1\"\n",
    "\n",
    "url_name = pdfurl.split(\"/\")[-1]\n",
    "if \".pdf\" not in url_name:\n",
    "    pdf = Path(url_name+\".pdf\")\n",
    "pdf = Path(url_name)\n",
    "response = requests.get(pdfurl)\n",
    "pdf.write_bytes(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfFileReader(url_name)\n",
    "cnt = 0\n",
    "text = \"\"\n",
    "while True:\n",
    "    content = reader.getPage(cnt).extractText()\n",
    "    text += content\n",
    "    if \"abstract\" in content.lower():\n",
    "        break\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pdfplumber.open(\"1811.04422v1\")\n",
    "page = pdf.pages[0]\n",
    "text = page.extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = pdf.pages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = page.extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'An Optimal Control View of Adversarial Machine Learning\\nXiaojin Zhu\\nDepartment of Computer Sciences, University of Wisconsin-Madison\\n8\\n1 Abstract\\n0\\nIdescribeanoptimalcontrolviewofadversarialmachinelearning,wherethedynamicalsystemisthe\\n2\\nmachine learner, the input are adversarial actions, and the control costs are deﬁned by the adversary’s\\n \\nv goals to do harm and be hard to detect. This view encompasses many types of adversarial machine\\no learning,includingtest-itemattacks,training-datapoisoning, andadversarial rewardshaping. Theview\\nN\\nencouragesadversarialmachinelearningresearchertoutilizeadvancesincontroltheoryandreinforcement\\n  learning.\\n1\\n1\\n \\n  1 Adversarial Machine Learning is not Machine Learning\\n]\\nG\\nL Machine learning has its mathematical foundation in concentration inequalities. This is a consequence of\\n. the independent and identically-distributed (i.i.d.) data assumption. In contrast, I suggest that adversarial\\ns\\nmachine learning may adopt optimal controlas its mathematical foundation [3,25]. There are telltale signs:\\nc\\n[ adversarialattacks tend to be subtle and have peculiar non-i.i.d. structures – as control input might be.\\n \\n \\n1\\nv\\n2 Optimal Control\\n2\\n2\\n4 I will focus on deterministic discrete-time optimal control because it matches many existing adversarial\\n4 attacks. Extensions to stochastic and continuous control are relevant to adversarial machine learning, too.\\n0 The system to be controlled is called the plant, which is deﬁned by the system dynamics:\\n.\\n1\\n1 xt+1 =f(xt,ut) (1)\\n8\\n1 where x ∈ X is the state of the system, u ∈ U is the control input, and U is the control constraint\\nt t t t t\\n: set. The function f deﬁnes the evolution of state under external control. The time index t ranges from 0\\nv\\ni to T −1, and the time horizon T can be ﬁnite or inﬁnite. The quality of control is speciﬁed by the running\\nX\\ncost:\\nr g (x ,u ) (2)\\na t t t\\nwhich deﬁnes the step-by-step control cost, and the terminal cost for ﬁnite horizon:\\ng (x ) (3)\\nT T\\nwhichdeﬁnesthe qualityofthe ﬁnalstate. The optimalcontrolproblemistoﬁndcontrolinputs u ...u\\n0 T−1\\nin order to minimize the objective:\\nT−1\\nmin g (x )+Xg (x ,u ) (4)\\nT T t t t\\nu0...uT−1 t=0\\ns.t. x =f(x ,u ), u ∈U , ∀t\\nt+1 t t t t\\nx given\\n0\\n1'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
    "punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "doc2bow expects an array of unicode tokens on input, not a single string",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-639a1b221ee0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Topic Modeling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfinal_topics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabstract\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Applications/anaconda3/envs/py3/lib/python3.7/site-packages/gensim/corpora/dictionary.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, documents, prune_at)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdocuments\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprune_at\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprune_at\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/py3/lib/python3.7/site-packages/gensim/corpora/dictionary.py\u001b[0m in \u001b[0;36madd_documents\u001b[0;34m(self, documents, prune_at)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0;31m# update Dictionary with the document\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc2bow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_update\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# ignore the result, here we only care about updating token ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         logger.info(\n",
      "\u001b[0;32m/Applications/anaconda3/envs/py3/lib/python3.7/site-packages/gensim/corpora/dictionary.py\u001b[0m in \u001b[0;36mdoc2bow\u001b[0;34m(self, document, allow_update, return_missing)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \"\"\"\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"doc2bow expects an array of unicode tokens on input, not a single string\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;31m# Construct (word, frequency) mapping.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: doc2bow expects an array of unicode tokens on input, not a single string"
     ]
    }
   ],
   "source": [
    "# Topic Modeling\n",
    "final_topics = []\n",
    "dictionary = corpora.Dictionary(abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]\n",
    "        LDA = gensim.models.ldamodel.LdaModel\n",
    "        LDA_fit = LDA(doc_term_matrix, num_topics=num_topics,\n",
    "                        id2word=dictionary,\n",
    "                        passes=200)\n",
    "        #t0, t1, t2, t3, t4 = LDA_fit.print_topics(num_topics=-1, num_words=num_words)\n",
    "        key_topics = []\n",
    "        topics_list = [t for t in LDA_fit.print_topics(num_topics=-1, num_words=num_words)]\n",
    "        for topic in topics_list:\n",
    "            topics = topic[1]\n",
    "            key_topics.append(topics)\n",
    "        for i in key_topics:\n",
    "            topic = i.replace('\"', '')\n",
    "            topic = topic.split('*')[1:]\n",
    "            topic = [j.split(\" + \")[0] for j in topic]\n",
    "            new_topic = []\n",
    "            for j in topic:\n",
    "                #topic_ = j.decode('utf-8')\n",
    "                if j == ' ':\n",
    "                    pass\n",
    "                elif j == '':\n",
    "                    pass\n",
    "                else:\n",
    "                    new_topic.append(j.strip())\n",
    "            final_topics.append(new_topic)\n",
    "        if final_topics[0][0] == \"\":\n",
    "            final_topics = None\n",
    "        else:\n",
    "            final_topics = [' + '.join(word for word in topic) for topic in final_topics]\n",
    "    return final_topics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
